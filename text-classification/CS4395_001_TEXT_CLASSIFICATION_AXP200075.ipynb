{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOg+jOt7GHqMxJSe6Y/qem+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alanperez/HLT-Portfolio/blob/main/text-classification/CS4395_001_TEXT_CLASSIFICATION_AXP200075.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Alan Perez** |\n",
        "**AXP200075** |\n",
        "**CS 4395.001** |\n",
        "**Assignment: Text Classification**"
      ],
      "metadata": {
        "id": "taq7MXoWCtRx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Text Classification**\n",
        "\n",
        "1.   Gain experience with Naïve Bayes, Logistic Regression, Neural Networks with sklearn using text data\n",
        "2.   Gain experience with text classification\n",
        "\n",
        "\n",
        "\n",
        "Dataset: https://www.kaggle.com/datasets/jp797498e/twitter-entity-sentiment-analysis\n"
      ],
      "metadata": {
        "id": "dupHeAMWFTpy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "ZP4g8m9pCyux",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddf1af88-1f8d-4c7b-8e3b-8ea5a51bcda2"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#load data\n",
        "\n",
        "# target column 2 which is sentiment and 3 which is tweet content\n",
        "data = pd.read_csv('twitter.csv',usecols=[2,3], names=['sentiment', 'tweet_content'],encoding='latin-1')\n",
        "\n",
        "# check for NaN values\n",
        "print(data.isna().sum())\n",
        "# check if there  are unexpected types\n",
        "\n",
        "print(data.applymap(type))\n",
        "# replace NaN with empty str\n",
        "data.fillna('', inplace=True)\n",
        "\n",
        "# convert columns to string type\n",
        "data['sentiment'] = data['sentiment'].astype(str)\n",
        "data['tweet_content'] = data['tweet_content'].astype(str)\n",
        "data = data.astype(str)\n",
        "display(data)\n",
        "\n",
        "# check the data types of each column\n",
        "print('data dtypes: ', data.dtypes)\n",
        "\n",
        "print('shape rows column: ', data.shape)\n",
        "print('head : ', data.head)\n",
        "print('tail: ', data.tail)\n",
        "\n",
        "# check for NaN values\n",
        "print(data.isna().sum())\n",
        "print(data.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 840
        },
        "id": "LLBuOVf_DjOa",
        "outputId": "a79be49d-c769-454f-d4d7-a911a980d2a5"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentiment          0\n",
            "tweet_content    686\n",
            "dtype: int64\n",
            "           sentiment  tweet_content\n",
            "0      <class 'str'>  <class 'str'>\n",
            "1      <class 'str'>  <class 'str'>\n",
            "2      <class 'str'>  <class 'str'>\n",
            "3      <class 'str'>  <class 'str'>\n",
            "4      <class 'str'>  <class 'str'>\n",
            "...              ...            ...\n",
            "74677  <class 'str'>  <class 'str'>\n",
            "74678  <class 'str'>  <class 'str'>\n",
            "74679  <class 'str'>  <class 'str'>\n",
            "74680  <class 'str'>  <class 'str'>\n",
            "74681  <class 'str'>  <class 'str'>\n",
            "\n",
            "[74682 rows x 2 columns]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      sentiment                                      tweet_content\n",
              "0      Positive  im getting on borderlands and i will murder yo...\n",
              "1      Positive  I am coming to the borders and I will kill you...\n",
              "2      Positive  im getting on borderlands and i will kill you ...\n",
              "3      Positive  im coming on borderlands and i will murder you...\n",
              "4      Positive  im getting on borderlands 2 and i will murder ...\n",
              "...         ...                                                ...\n",
              "74677  Positive  Just realized that the Windows partition of my...\n",
              "74678  Positive  Just realized that my Mac window partition is ...\n",
              "74679  Positive  Just realized the windows partition of my Mac ...\n",
              "74680  Positive  Just realized between the windows partition of...\n",
              "74681  Positive  Just like the windows partition of my Mac is l...\n",
              "\n",
              "[74682 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-788f5d2d-26ee-496c-8007-d1064bff4178\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>tweet_content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Positive</td>\n",
              "      <td>im getting on borderlands and i will murder yo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Positive</td>\n",
              "      <td>I am coming to the borders and I will kill you...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Positive</td>\n",
              "      <td>im getting on borderlands and i will kill you ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Positive</td>\n",
              "      <td>im coming on borderlands and i will murder you...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Positive</td>\n",
              "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74677</th>\n",
              "      <td>Positive</td>\n",
              "      <td>Just realized that the Windows partition of my...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74678</th>\n",
              "      <td>Positive</td>\n",
              "      <td>Just realized that my Mac window partition is ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74679</th>\n",
              "      <td>Positive</td>\n",
              "      <td>Just realized the windows partition of my Mac ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74680</th>\n",
              "      <td>Positive</td>\n",
              "      <td>Just realized between the windows partition of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74681</th>\n",
              "      <td>Positive</td>\n",
              "      <td>Just like the windows partition of my Mac is l...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>74682 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-788f5d2d-26ee-496c-8007-d1064bff4178')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-788f5d2d-26ee-496c-8007-d1064bff4178 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-788f5d2d-26ee-496c-8007-d1064bff4178');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data dtypes:  sentiment        object\n",
            "tweet_content    object\n",
            "dtype: object\n",
            "sentiment        0\n",
            "tweet_content    0\n",
            "dtype: int64\n",
            "Index(['sentiment', 'tweet_content'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization of the graph"
      ],
      "metadata": {
        "id": "lSkZwnUDFYi5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sb.catplot(x=\"sentiment\", kind=\"count\", data=data)\n",
        "plt.xlabel('Sentiment')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Distribution of Twitter Sentiment')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "x3o2C370FcUF",
        "outputId": "e86be00e-e388-42aa-ca74-b06ddd3076f8"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train and Test Sets"
      ],
      "metadata": {
        "id": "1atGU4QKTXS3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Divide into train and test sets\n",
        "# set up X and Y\n",
        "X = data[\"tweet_content\"]\n",
        "y = data[\"sentiment\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, train_size=0.8, random_state=1234)\n",
        "\n",
        "# take a peek at the data\n",
        "# this is a very sparse matrix because most of the 8613 words don't occur in each sms message\n",
        "\n",
        "print('train size:', X_train.shape)\n",
        "print(X_train)\n",
        "\n",
        "print('\\ntest size:', X_test.shape)\n",
        "print(X_test[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CL_4HtzbTYAh",
        "outputId": "523b2753-fa71-4a5b-f851-0c2aa8e619b2"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train size: (59745,)\n",
            "22900    CS : FC GO Wingman Romania - Tech Sunt 2012 no...\n",
            "49433                                    A ZAYN IN MY DAY.\n",
            "12669    RhandlerR another one with my guy! RhandlerR R...\n",
            "4633                                   Are you kidding me?\n",
            "820      I went to bed at 4am. 5 hours before that at 9...\n",
            "                               ...                        \n",
            "55985    Fuck YouTube that twitch me donât wanna use ...\n",
            "32399                                                   to\n",
            "60620                      Check out my Facebook to see my\n",
            "34086    @FortniteGame this new update makes everyone l...\n",
            "58067    @Rainbow6Game is there great way to stop the p...\n",
            "Name: tweet_content, Length: 59745, dtype: object\n",
            "\n",
            "test size: (14937,)\n",
            "36232    Microsoft onedrive : 7 A hate thread. 1 / ME 3462\n",
            "55480    A Tried cod warzone with controller today, how...\n",
            "27065    not am really looking forward to that. I loved...\n",
            "30344    I have no idea what this is but is positive an...\n",
            "34082    my twin tasks are so ugly, a sniper rifle and ...\n",
            "Name: tweet_content, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text-Preprocessing"
      ],
      "metadata": {
        "id": "FKfgHu_BUr55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "\n",
        "# Set stopwords as a list\n",
        "stopwords = set(stopwords.words('english'))\n",
        "vectorizer = TfidfVectorizer(stop_words=list(stopwords))\n",
        "\n",
        "# Ensure input data is in the correct format\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, train_size=0.8, random_state=1234)\n",
        "\n",
        "# Apply the TfidfVectorizer\n",
        "X_train = vectorizer.fit_transform(X_train)\n",
        "X_test = vectorizer.transform(X_test)\n",
        "\n",
        "# peek at data\n",
        "print('train size:', X_train.shape)\n",
        "print(X_train.toarray()[:5])\n",
        "\n",
        "print('\\ntest size:', X_test.shape)\n",
        "print(X_test.toarray()[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DB-awNNUvVW",
        "outputId": "a9146825-81f3-458a-8651-a759af7aacbf"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train size: (59745, 30687)\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            "test size: (14937, 30687)\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Naive Bayes"
      ],
      "metadata": {
        "id": "nM8s1RfjYLSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import BernoulliNB\n",
        "\n",
        "naive_bayes = BernoulliNB()\n",
        "naive_bayes.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "FV9kn0PcYQq9",
        "outputId": "c5d93b19-a312-4aff-9fe1-5d2edf28ee7e"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BernoulliNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-16 {color: black;background-color: white;}#sk-container-id-16 pre{padding: 0;}#sk-container-id-16 div.sk-toggleable {background-color: white;}#sk-container-id-16 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-16 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-16 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-16 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-16 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-16 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-16 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-16 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-16 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-16 div.sk-item {position: relative;z-index: 1;}#sk-container-id-16 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-16 div.sk-item::before, #sk-container-id-16 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-16 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-16 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-16 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-16 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-16 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-16 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-16 div.sk-label-container {text-align: center;}#sk-container-id-16 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-16 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-16\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BernoulliNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" checked><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BernoulliNB</label><div class=\"sk-toggleable__content\"><pre>BernoulliNB()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NB Model\n",
        "\n",
        "The Bernouli NB model has a 73.8% accuracy compared to the other model along with higher precision. "
      ],
      "metadata": {
        "id": "h8cgSTbRY5Tb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1csRw3UIxvOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import math\n",
        "prior_p = sum(y_train == 1)/len(y_train)\n",
        "print('prior sentiment:', prior_p, 'log of prior:', math.log(prior_p + 1e-6 ))\n",
        "\n",
        "# the model prior matches the prior calculated above\n",
        "naive_bayes.class_log_prior_[1]\n",
        "\n",
        "\n",
        "# make predictions on the test data\n",
        "pred = naive_bayes.predict(X_test)\n",
        "\n",
        "# confusion matrix\n",
        "print('confusion matrix: ', confusion_matrix(y_test, pred))\n",
        "\n",
        "\n",
        "# accuracy score\n",
        "\n",
        "print('\\naccuracy score: ', accuracy_score(y_test, pred))\n",
        "\n",
        "# precision\n",
        "print('\\nprecision score : ', precision_score(y_test, pred, average='macro'))\n",
        "# recall\n",
        "print('\\nrecall score: ', recall_score(y_test, pred, average='macro'))\n",
        "      \n",
        "print('\\nf1 score: ', f1_score(y_test, pred, average='macro'))\n",
        "\n",
        "# precision \n",
        "print('\\nprecision score: ', precision_score(y_test, pred, average=None))\n",
        "# recall\n",
        "print('\\nrecall score: ', recall_score(y_test, pred,average=None))\n",
        "      \n",
        "print('\\nf1 score: ', f1_score(y_test, pred, average=None))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_N7FrkmY8kT",
        "outputId": "efd6ba4e-256f-4772-9a4e-a46194aca58e"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prior sentiment: 0.0 log of prior: -13.815510557964274\n",
            "confusion matrix:  [[1489  385   49  722]\n",
            " [  46 3659  106  707]\n",
            " [ 117  497 2208  875]\n",
            " [  38  301  101 3637]]\n",
            "\n",
            "accuracy score:  0.7359576889602999\n",
            "\n",
            "precision score :  0.7862587391858183\n",
            "\n",
            "recall score:  0.7155347747769816\n",
            "\n",
            "f1 score:  0.7279159873371306\n",
            "\n",
            "precision score:  [0.88106509 0.75567947 0.8961039  0.6121865 ]\n",
            "\n",
            "recall score:  [0.56294896 0.80987162 0.59724101 0.89207751]\n",
            "\n",
            "f1 score:  [0.68696655 0.78183761 0.71676676 0.72609303]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I'll be using the Multinomial Bayes classifier and evaluating the model for the second attempt. Will have the average set to none for the first one then setting the other portion to micro\n",
        "\n",
        "\n",
        "'micro': Calculate metrics globally by counting the total true positives, false negatives and false positives.\n",
        "\n",
        "'macro': Calculate metrics for each label, and find their unweighted mean. This does not take label imbalance into account."
      ],
      "metadata": {
        "id": "Pb54IAVrtJ4p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "nb_v2 = MultinomialNB()\n",
        "nb_v2.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "iuq0tnJVs03E",
        "outputId": "77703c0d-a2f0-4726-fe74-c00268d35288"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-17 {color: black;background-color: white;}#sk-container-id-17 pre{padding: 0;}#sk-container-id-17 div.sk-toggleable {background-color: white;}#sk-container-id-17 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-17 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-17 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-17 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-17 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-17 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-17 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-17 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-17 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-17 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-17 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-17 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-17 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-17 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-17 div.sk-item {position: relative;z-index: 1;}#sk-container-id-17 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-17 div.sk-item::before, #sk-container-id-17 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-17 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-17 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-17 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-17 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-17 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-17 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-17 div.sk-label-container {text-align: center;}#sk-container-id-17 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-17 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-17\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" checked><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make predictions on the test data\n",
        "predv2 = nb_v2.predict(X_test)\n",
        "\n",
        "\n",
        "# confusion matrix\n",
        "print('confusion matrix: ', confusion_matrix(y_test, predv2))\n",
        "\n",
        "#[positive, neutral, negative, irrelevant] \n",
        "# accuracy score\n",
        "\n",
        "print('\\naccuracy score: ', accuracy_score(y_test, predv2))\n",
        "\n",
        "# precision\n",
        "print('\\nprecision score : ', precision_score(y_test, predv2, average=None))\n",
        "# recall\n",
        "print('\\nrecall score: ', recall_score(y_test, predv2,average=None))\n",
        "      \n",
        "print('\\nf1 score: ', f1_score(y_test, predv2, average=None))\n",
        "\n",
        "# weighted\n",
        "print('\\nprecision score micro: ', precision_score(y_test, predv2, average=\"micro\"))\n",
        "# recall\n",
        "print('\\nrecall score micro: ', recall_score(y_test, predv2,average=\"micro\"))\n",
        "      \n",
        "print('\\nf1 score micro: ', f1_score(y_test, predv2, average=\"micro\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb3TWs2au17e",
        "outputId": "aca9bad3-4b6f-4841-db6c-75dec9727737"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "confusion matrix:  [[1197  736  148  564]\n",
            " [  11 4067  130  310]\n",
            " [  20  762 2402  513]\n",
            " [  17  609  124 3327]]\n",
            "\n",
            "accuracy score:  0.7359576889602999\n",
            "\n",
            "precision score :  [0.96144578 0.65873016 0.85663338 0.70577005]\n",
            "\n",
            "recall score:  [0.45255198 0.90017707 0.64971599 0.81604121]\n",
            "\n",
            "f1 score:  [0.61542416 0.76075571 0.73896324 0.75691048]\n",
            "\n",
            "precision score micro:  0.7359576889602999\n",
            "\n",
            "recall score micro:  0.7359576889602999\n",
            "\n",
            "f1 score micro:  0.7359576889602999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression\n",
        "\n",
        "I'll be using LR with and without pipelines in two attempts\n",
        "\n"
      ],
      "metadata": {
        "id": "eLau0B16xwyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss\n",
        "\n",
        "#train\n",
        "classifier = LogisticRegression(solver='lbfgs', class_weight='balanced',max_iter=1000)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# evaluate\n",
        "pred = classifier.predict(X_test)\n",
        "print('accuracy score: ', accuracy_score(y_test, pred))\n",
        "print('precision score: ', precision_score(y_test, pred, average=None))\n",
        "print('recall score: ', recall_score(y_test, pred, average=None))\n",
        "print('f1 score: ', f1_score(y_test, pred, average=None))\n",
        "probs = classifier.predict_proba(X_test)\n",
        "print('log loss: ', log_loss(y_test, probs))\n",
        "\n",
        "\n",
        "\n",
        "print('accuracy score micro: ', accuracy_score(y_test, pred))\n",
        "print('precision score micro: ', precision_score(y_test, pred, average='micro'))\n",
        "print('recall score micro: ', recall_score(y_test, pred,average='micro'))\n",
        "print('f1 score micro: ', f1_score(y_test, pred,average='micro'))\n",
        "probs = classifier.predict_proba(X_test)\n",
        "print('log loss micro: ', log_loss(y_test, probs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4abQBaXBfc6h",
        "outputId": "4326e99a-b259-4739-dad6-dbf8e3a29acb"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy score:  0.7903193412331794\n",
            "precision score:  [0.67575015 0.84694594 0.81042927 0.80621339]\n",
            "recall score:  [0.83440454 0.80101815 0.76088721 0.77655139]\n",
            "f1 score:  [0.74674336 0.82334205 0.78487723 0.79110445]\n",
            "log loss:  0.6726464750888004\n",
            "accuracy score micro:  0.7903193412331794\n",
            "precision score micro:  0.7903193412331794\n",
            "recall score micro:  0.7903193412331794\n",
            "f1 score micro:  0.7903193412331795\n",
            "log loss micro:  0.6726464750888004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This attempt will use pipeline"
      ],
      "metadata": {
        "id": "hmCwcpSMh9NL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "\n",
        "# read in data, split raw data into train and test, then use pipeline to transform\n",
        "pipe1 = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(stop_words=list(stopwords), binary=True)),\n",
        "    ('logreg', LogisticRegression(solver='lbfgs', class_weight='balanced', max_iter=1000)),\n",
        "])\n",
        "\n",
        "# Use the raw text data in train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, train_size=0.8, random_state=1234)\n",
        "\n",
        "pipe1.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "bDnGIT28iAOX",
        "outputId": "5b808c1d-9ec8-457b-8d13-4edf749da9d7"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf',\n",
              "                 TfidfVectorizer(binary=True,\n",
              "                                 stop_words=['am', 'which', 'been', 'here',\n",
              "                                             'herself', 'you', 'mightn', 'be',\n",
              "                                             'into', \"hadn't\", 'yourself',\n",
              "                                             'for', 'her', 'were', 'being',\n",
              "                                             'of', 'between', 'above', 've',\n",
              "                                             'hadn', 'm', 'an', 'does', 'was',\n",
              "                                             'weren', 'before', 'so', \"it's\",\n",
              "                                             'isn', 'further', ...])),\n",
              "                ('logreg',\n",
              "                 LogisticRegression(class_weight='balanced', max_iter=1000))])"
            ],
            "text/html": [
              "<style>#sk-container-id-18 {color: black;background-color: white;}#sk-container-id-18 pre{padding: 0;}#sk-container-id-18 div.sk-toggleable {background-color: white;}#sk-container-id-18 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-18 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-18 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-18 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-18 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-18 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-18 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-18 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-18 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-18 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-18 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-18 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-18 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-18 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-18 div.sk-item {position: relative;z-index: 1;}#sk-container-id-18 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-18 div.sk-item::before, #sk-container-id-18 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-18 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-18 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-18 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-18 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-18 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-18 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-18 div.sk-label-container {text-align: center;}#sk-container-id-18 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-18 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-18\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
              "                 TfidfVectorizer(binary=True,\n",
              "                                 stop_words=[&#x27;am&#x27;, &#x27;which&#x27;, &#x27;been&#x27;, &#x27;here&#x27;,\n",
              "                                             &#x27;herself&#x27;, &#x27;you&#x27;, &#x27;mightn&#x27;, &#x27;be&#x27;,\n",
              "                                             &#x27;into&#x27;, &quot;hadn&#x27;t&quot;, &#x27;yourself&#x27;,\n",
              "                                             &#x27;for&#x27;, &#x27;her&#x27;, &#x27;were&#x27;, &#x27;being&#x27;,\n",
              "                                             &#x27;of&#x27;, &#x27;between&#x27;, &#x27;above&#x27;, &#x27;ve&#x27;,\n",
              "                                             &#x27;hadn&#x27;, &#x27;m&#x27;, &#x27;an&#x27;, &#x27;does&#x27;, &#x27;was&#x27;,\n",
              "                                             &#x27;weren&#x27;, &#x27;before&#x27;, &#x27;so&#x27;, &quot;it&#x27;s&quot;,\n",
              "                                             &#x27;isn&#x27;, &#x27;further&#x27;, ...])),\n",
              "                (&#x27;logreg&#x27;,\n",
              "                 LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
              "                 TfidfVectorizer(binary=True,\n",
              "                                 stop_words=[&#x27;am&#x27;, &#x27;which&#x27;, &#x27;been&#x27;, &#x27;here&#x27;,\n",
              "                                             &#x27;herself&#x27;, &#x27;you&#x27;, &#x27;mightn&#x27;, &#x27;be&#x27;,\n",
              "                                             &#x27;into&#x27;, &quot;hadn&#x27;t&quot;, &#x27;yourself&#x27;,\n",
              "                                             &#x27;for&#x27;, &#x27;her&#x27;, &#x27;were&#x27;, &#x27;being&#x27;,\n",
              "                                             &#x27;of&#x27;, &#x27;between&#x27;, &#x27;above&#x27;, &#x27;ve&#x27;,\n",
              "                                             &#x27;hadn&#x27;, &#x27;m&#x27;, &#x27;an&#x27;, &#x27;does&#x27;, &#x27;was&#x27;,\n",
              "                                             &#x27;weren&#x27;, &#x27;before&#x27;, &#x27;so&#x27;, &quot;it&#x27;s&quot;,\n",
              "                                             &#x27;isn&#x27;, &#x27;further&#x27;, ...])),\n",
              "                (&#x27;logreg&#x27;,\n",
              "                 LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(binary=True,\n",
              "                stop_words=[&#x27;am&#x27;, &#x27;which&#x27;, &#x27;been&#x27;, &#x27;here&#x27;, &#x27;herself&#x27;, &#x27;you&#x27;,\n",
              "                            &#x27;mightn&#x27;, &#x27;be&#x27;, &#x27;into&#x27;, &quot;hadn&#x27;t&quot;, &#x27;yourself&#x27;, &#x27;for&#x27;,\n",
              "                            &#x27;her&#x27;, &#x27;were&#x27;, &#x27;being&#x27;, &#x27;of&#x27;, &#x27;between&#x27;, &#x27;above&#x27;,\n",
              "                            &#x27;ve&#x27;, &#x27;hadn&#x27;, &#x27;m&#x27;, &#x27;an&#x27;, &#x27;does&#x27;, &#x27;was&#x27;, &#x27;weren&#x27;,\n",
              "                            &#x27;before&#x27;, &#x27;so&#x27;, &quot;it&#x27;s&quot;, &#x27;isn&#x27;, &#x27;further&#x27;, ...])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000)</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = pipe1.predict(X_test)\n",
        "print('accuracy score: ', accuracy_score(y_test, pred))\n",
        "print('precision score: ', precision_score(y_test, pred, average=None))\n",
        "print('recall score: ', recall_score(y_test, pred,average=None))\n",
        "print('f1 score: ', f1_score(y_test, pred,average=None))\n",
        "probs = pipe1.predict_proba(X_test)\n",
        "print('log loss: ', log_loss(y_test, probs))\n",
        "\n",
        "\n",
        "print('accuracy score micro: ', accuracy_score(y_test, pred))\n",
        "print('precision score micro: ', precision_score(y_test, pred, average='micro'))\n",
        "print('recall score micro: ', recall_score(y_test, pred,average='micro'))\n",
        "print('f1 score micro: ', f1_score(y_test, pred,average='micro'))\n",
        "probs = pipe1.predict_proba(X_test)\n",
        "print('log loss micro: ', log_loss(y_test, probs))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0H6wq_rjqXTV",
        "outputId": "8ceab3b5-810b-44e0-ce37-4eae984e35fb"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy score:  0.7977505523197429\n",
            "precision score:  [0.77024616 0.85114862 0.74924166 0.80828221]\n",
            "recall score:  [0.81625709 0.80367419 0.80173113 0.77557027]\n",
            "f1 score:  [0.79258443 0.82673042 0.7745982  0.79158843]\n",
            "log loss:  0.6686961671968155\n",
            "accuracy score micro:  0.7977505523197429\n",
            "precision score micro:  0.7977505523197429\n",
            "recall score micro:  0.7977505523197429\n",
            "f1 score micro:  0.7977505523197429\n",
            "log loss micro:  0.6686961671968155\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the results Logistic Regression gives better results than Naive Bayes.\n",
        "\n",
        "The Logistic Regression model performs better with an accuracy of 0.7978, while the Naive Bayes model has an accuracy of 0.7360. This means that the LR model classifies a higher percentage of instances correctly.\n",
        "\n",
        "Regarding the other scores the LR performs better across all classes. While the Naive bayes has a very high precision score for the first class, its recall score is much lower. This means that the NB model is overly conservative in predicting the first class which has a negative effect on the performance.\n"
      ],
      "metadata": {
        "id": "L-a85dDQ0ejG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Network"
      ],
      "metadata": {
        "id": "8okI5nx83Ygz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# text preprocessing\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Download the stopwords if not already downloaded\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Get the list of English stopwords\n",
        "stopwords_list = stopwords.words('english')\n",
        "\n",
        "# Create the TfidfVectorizer with the list of stopwords\n",
        "vectorizer = TfidfVectorizer(stop_words=stopwords_list, binary=True)\n",
        "\n",
        "# target column 2 which is sentiment and 3 which is tweet content\n",
        "data = pd.read_csv('twitter.csv',usecols=[2,3], names=['sentiment', 'tweet_content'],encoding='latin-1')\n",
        "\n",
        "# Replace NaN with empty str\n",
        "data.fillna('', inplace=True)\n",
        "\n",
        "# Set up X and y\n",
        "X = vectorizer.fit_transform(data.tweet_content)\n",
        "y = data.sentiment\n",
        "\n",
        "# convert columns to string type\n",
        "data['sentiment'] = data['sentiment'].astype(str)\n",
        "data['tweet_content'] = data['tweet_content'].astype(str)\n",
        "\n",
        "\n",
        "# Set up X and y\n",
        "X = vectorizer.fit_transform(data.tweet_content)\n",
        "y = data.sentiment\n",
        "\n",
        "\n",
        "# Ensure input data is in the correct format\n",
        "# Apply the TfidfVectorizer\n",
        "\n",
        "# divide into train and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, train_size=0.8, random_state=1234)\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "classifier = MLPClassifier(solver='lbfgs', alpha=1e-5, max_iter=2000,\n",
        "                   hidden_layer_sizes=(15, 2), random_state=1)\n",
        "classifier.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "GixY4n113afI",
        "outputId": "4e69fa07-bbf1-4d77-8a2a-917a541c5353"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(15, 2), max_iter=2000,\n",
              "              random_state=1, solver='lbfgs')"
            ],
            "text/html": [
              "<style>#sk-container-id-20 {color: black;background-color: white;}#sk-container-id-20 pre{padding: 0;}#sk-container-id-20 div.sk-toggleable {background-color: white;}#sk-container-id-20 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-20 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-20 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-20 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-20 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-20 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-20 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-20 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-20 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-20 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-20 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-20 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-20 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-20 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-20 div.sk-item {position: relative;z-index: 1;}#sk-container-id-20 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-20 div.sk-item::before, #sk-container-id-20 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-20 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-20 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-20 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-20 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-20 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-20 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-20 div.sk-label-container {text-align: center;}#sk-container-id-20 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-20 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-20\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(alpha=1e-05, hidden_layer_sizes=(15, 2), max_iter=2000,\n",
              "              random_state=1, solver=&#x27;lbfgs&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" checked><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(alpha=1e-05, hidden_layer_sizes=(15, 2), max_iter=2000,\n",
              "              random_state=1, solver=&#x27;lbfgs&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "pred = classifier.predict(X_test)\n",
        "print('accuracy score: ', accuracy_score(y_test, pred))\n",
        "print('precision score: ', precision_score(y_test, pred, average=None))\n",
        "print('recall score: ', recall_score(y_test, pred, average=None))\n",
        "print('f1 score: ', f1_score(y_test, pred, average=None))\n",
        "\n",
        "\n",
        "print('accuracy score ', accuracy_score(y_test, pred))\n",
        "print('precision score micro: ', precision_score(y_test, pred, average='micro'))\n",
        "print('recall score micro: ', recall_score(y_test, pred, average='micro'))\n",
        "print('f1 score micro: ', f1_score(y_test, pred, average='micro'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OUWicJ_6AZy",
        "outputId": "d274c3f7-2e66-4788-9173-734c5a8e9beb"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy score:  0.6910356832027851\n",
            "precision score:  [0.77754504 0.78903346 0.64365833 0.59383519]\n",
            "recall score:  [0.70170132 0.75166003 0.60535569 0.6946284 ]\n",
            "f1 score:  [0.73767886 0.76989345 0.62391971 0.6402894 ]\n",
            "accuracy score  0.6910356832027851\n",
            "precision score micro:  0.6910356832027851\n",
            "recall score micro:  0.6910356832027851\n",
            "f1 score micro:  0.6910356832027851\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Neural Network returns a moderate performance which an accuracy score of 69.1%. I've displayed the other scores of each class seperately and the micro averaged scores 'positive', 'neutral', 'negative' and 'irrelevant'\n",
        "\n",
        "The performance of the classifier could have been further improved by exploring alternative methods."
      ],
      "metadata": {
        "id": "vEIvjiH_Bsow"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysis - Conlusion\n",
        "\n",
        "\n",
        "    Logistic Regression:\n",
        "        Accuracy: 79.78%\n",
        "        Precision: [0.770, 0.851, 0.749, 0.808]\n",
        "        Recall: [0.816, 0.804, 0.802, 0.776]\n",
        "        F1 Score: [0.793, 0.827, 0.775, 0.792]\n",
        "        Log loss: 0.6687\n",
        "        Micro-averaged Precision, Recall, and F1 score are all equal to 79.78%.\n",
        "\n",
        "    Naive Bayes:\n",
        "        Accuracy: 73.60%\n",
        "        Precision: [0.961, 0.659, 0.857, 0.706]\n",
        "        Recall: [0.453, 0.900, 0.650, 0.816]\n",
        "        F1 Score: [0.615, 0.761, 0.739, 0.757]\n",
        "        Micro-averaged Precision, Recall, and F1 score are all equal to 73.60%.\n",
        "\n",
        "    Neural Network (MLPClassifier):\n",
        "        Accuracy: 69.10%\n",
        "        Precision: [0.778, 0.789, 0.644, 0.594]\n",
        "        Recall: [0.702, 0.752, 0.605, 0.695]\n",
        "        F1 Score: [0.738, 0.770, 0.624, 0.640]\n",
        "        Micro-averaged Precision, Recall, and F1 score are all equal to 69.10%.\n",
        "\n",
        "Out of the three methods, the Logistic Regression performs the best in terms of accuracy, precision, recall, and F1 score. The second best performing would be Naive Bayes, and lastly the lowest performing is Neural Network\n",
        "\n",
        "The dataset that I chose was a twitter analysis sentiment and it seems that it worked well with this data set since LR assumes a linear releationship. Generally, Logistic Regression is faster to train, interpret, and less prone to overfitting compared to Neural Networks. Each model highly depends on the specific problem and dataset so that's the reason why the results are how they are.\n",
        "\n",
        "The Neural network captures more complex patterns and it might have had a different outcome if a more complex dataset was used. Using NN requires more data and computational resources to train, but its also prone to overfitting. \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BS7erNFVCbmz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5lCRLfKhCQVv"
      },
      "execution_count": 151,
      "outputs": []
    }
  ]
}